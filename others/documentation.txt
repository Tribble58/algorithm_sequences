ДОКУМЕНТАЦИЯ К РЕШЕНИЮ ПО ТЕСТОВОМУ КЕЙСУ КОМПАНИИ ARTEC3D


=======1. Формулировка задачи========

Используя данные телеметрии, определить топ 10 самых популярных сценариев запуска алгоритмов в рамках одной сессии.  
Визуализировать полученные данные на дэшборде. Инструмент и тип графиков на усмотрение автора.

В ответе необходимо указать:

- Общее количество сессий.
- Количество выполнений каждого сценария из топ 10 списка.
- Последовательность запуска алгоритмов для каждого сценария из топ 10.

=======2. Данные=====================

Входные данные представляют из себя текстовые файлы формата '.log', каждый файл соответствует одной сессии.

=======3. Описание решения===========

Последовательность работы представляет из себя следующий алгоритм:

3.1. выгрузка и трансформации данных.
Предварительно в переменную log_paths (список) записываются все пути, названия которых содержат '.log'. Впоследствии каждый текстовый файл считывается и записывается в переменную log.
Для каждого файла происходит построчное считывание, для каждой строки производится поиск по шаблону при помощи регулярных выражений, символы ']', '[' заменяются на пробелы, далее разделяются про этому пробелу и заносятся в DataFrame (табличная структура пакета pandas).

Для удобства создается временный инстанс SQL таблицы (sqlite3), в которую транспортируются данные из DataFrame. Над этой таблицей выполняются запросы (ex1_sql_query) для трансформации данных в необходимый вид.

3.2. загрузка данных.
Таблица из SQL инстанса сохраняется в формат csv.

3.3 визуализация.
Отображение данных выполнено в ПО Tableau. После выполнения основного скрипта генерируется таблица top10.csv, которая впоследствии выводится на графики. На графиках представлены суммарное количество сессий, которые были обработаны, количество выполнений 10 самых популярных алгоритмов по всем сессиям, а также сами последовательности этих алгоритмов.

========4. Предлагаемые улучшения===

Загрузку логов можно реализовать параллельно, поскольку последовательность загрузки не имеет значения. Реализовать можно как в Spark, так и библиотеками для параллезации.
Частично трансформация производилась во время загрузки (например, использование регулярных выражений). Поскольку не все файлы однотипны, возможно загрузить логи в сырое хранилище как есть (например, HDFS), далее обрабатывать их без потери ошибочно загруженных файлов.
Помимо этого, предлагается реализация дополнительных графиков на дешбордах, а также иное решение, которое не было включено в задачу. Об этом - в личной встрече :)


